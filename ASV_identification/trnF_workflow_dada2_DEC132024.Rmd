---
title: "trnF data analysis"
author: "Pedro Rodrigues"
output:
  BiocStyle::html_document:
    toc: true
    toc_depth: 3
    fig_caption: yes

fontsize: 14pt
---

# Introduction

We extracted DNA from three batches of burrower bugs (Cydnidae) collected in peanut fields grown in southern GA, USA. A portion of the chloroplast _trnF_ gene was sequenced from these samples, to characterize the diet of these insects. Here, these three batches of sequencing data, PBB1, PBB2, and PBB3, are quality-trimmed and noise-filtered before being combined and classified into plant taxa. Two species of burrower bugs are represented in this data, and we test whether their diet is different, how often they consume peanuts, and whether their diet changes across time and sampling location.


# Setup

Prepare environment
Load packages

```{r init, warning=FALSE, message=FALSE}

setwd("/Users/ento-user/Documents/Github_Burrower_Bug/Burrower-Bugs-diet-and-pop-gen/ASV_identification")
set.seed("1805")

library(dada2);packageVersion("dada2") # ‘1.30.0’
library(Biostrings); packageVersion("Biostrings") #‘2.70.3’
library(ShortRead); packageVersion("ShortRead") #‘1.60.0’
library(ggplot2); packageVersion("ggplot2") #‘3.5.0’
library(reshape2); packageVersion("reshape2") #‘1.4.4’
library(gridExtra); packageVersion("gridExtra") #‘2.3’
library(phyloseq); packageVersion("phyloseq") #‘1.46.0’
library(dplyr); packageVersion("dplyr") #‘1.1.4’
library(vegan); packageVersion("vegan")
```

```{r more preparation, warning=FALSE, message=FALSE}
pathPBB1 <- "../diet_data/PBB1"
pathPBB2 <- "../diet_data/PBB2"
pathPBB3 <- "../diet_data/PBB3"
path.out <- "Figures/"
path.rds <- "RDS/"
fnsPBB1 <- list.files(pathPBB1, pattern=".fastq", full.names=TRUE)
fnsPBB2 <- list.files(pathPBB2, pattern=".fastq", full.names=TRUE)
fnsPBB3 <- list.files(pathPBB3, pattern=".fastq", full.names=TRUE)
B49873_e <- "GGTTCAAGTCCCTCTATCCC"
A50272_f <- "ATTTGAACTGGTGACACGAG"
rc <- dada2:::rc
theme_set(theme_bw())
```


# Primer removal and filtering
## Remove Primers and Filter (PBB3)

Remove primers and orient reads:
```{r primers3}
nops3 <- file.path(pathPBB3, "noprimers", basename(fnsPBB3))
prim3 <- removePrimers(fnsPBB3, nops3, primer.fwd=B49873_e, primer.rev=dada2:::rc(A50272_f), orient=TRUE)
```

Inspect length distribution.
```{r length-distro3}
lens.fn3 <- lapply(nops3, function(fn) nchar(getSequences(fn)))
lens3 <- do.call(c, lens.fn3)
hist(lens3, 100)
min(lens3)
max(lens3)
```

There is a wide range of lengths in these samples - this is expected. Let's check what is the minimum size expected based on the trnF database that I created using the NCBI RefSeq chloroplasts genomes

In UNIX, I get the following result (see below)

(base) pd88715@ss-sub3 ref_seq_plastids$ cat trnF_db11Feb22.fa | awk '$0 ~ ">" {if (NR > 1) {print c;} c=0;printf substr($0,2,100) "\t"; } $0 !~ ">" {c+=length($0);} END { print c; }' | cut -f 2 | sort -n | head
101
102
102
102
102
102
102
103
103
103

>NOTE: one of the settings for building this reference trnF intergenic gene database is removing sequences smaller than 100bp

### Filter and Trim PBB3
>Note on maxEE - for fungal identification using ITS1 it was found that increasing maxEE = 8 increased the number of reads per taxa expected to be present in the sample (Rolling et al. 2021); previously I used maxEE=2, and had to rarefy data in downstream analysis to 100 sequences/sample, which was very low; I am using maxEE=8 to increase the number of reads per plant species
source  https://insight.jci.org/articles/view/151663

```{r filter3}
filts3 <- file.path(pathPBB3, "noprimers", "filtered", basename(fnsPBB3))
track3 <- filterAndTrim(nops3, filts3, minQ=3, minLen=100, maxN=0, rm.phix=FALSE, maxEE=8)
track3
```

## Denoise data with DADA2

Dereplicate
```{r derep3, message=FALSE}
drp3 <- derepFastq(filts3, verbose=TRUE)
```


Learn errors
```{r learn-err3}
err3 <- learnErrors(drp3, errorEstimationFunction=PacBioErrfun, BAND_SIZE=32, multithread=TRUE)
saveRDS(err3, file.path(path.rds, "PBB3_err2.rds")) #name changes here, keeping previous files generated by version 1 of this workflow
```

Inspect errors
```{r see-err3}
plotErrors(err3)
```

Looks good: base error decreases with higher base quality scores.

Denoise
```{r dada2-sample3}
dd3 <- dada(drp3, err=err3, BAND_SIZE=32, multithread=TRUE)
saveRDS(dd3, file.path(path.rds, "PBB3_dd3_2.rds"))
```
Not a lot of losses. PacBio stringent pre-filtering probably already excluded most of the low quality sequences.
There is generally more reads than unique reads, which is a good sign.

Read tracking for PBB3
```{r}
cbind(ccs=prim3[,1], primers=prim3[,2], filtered=track3[,2], denoised=sapply(dd3, function(x) sum(x$denoised)))
```

Sequence table for PBB3:
```{r seqtab3}
st3 <- makeSequenceTable(dd3); dim(st3)
```

Here is a good point to save the sequence table and use this table when merging with other datasets (PBB1 and PBB2).
```{r save seq table3}
saveRDS(st3, "RDS/PBB3_2.rds")
```


------------------------------------------


## Process the other two datasets (PBB1 and PBB2), and combine all results into one single dataset

*Starting with PBB1*

Remove primers and orient reads:
```{r primers1, message=FALSE, warning=FALSE}
nops1 <- file.path(pathPBB1, "noprimers", basename(fnsPBB1))
prim1 <- removePrimers(fnsPBB1, nops1, primer.fwd=B49873_e, primer.rev=dada2:::rc(A50272_f), orient=TRUE)
```

Inspect length distribution.
```{r length-distro1}
lens.fn <- lapply(nops1, function(fn) nchar(getSequences(fn)))
lens <- do.call(c, lens.fn)
hist(lens, 100)
min(lens)
max(lens)
```


Filter and Trim
maxEE=8
```{r filter1}
filts1 <- file.path(pathPBB1, "noprimers", "filtered", basename(fnsPBB1))
track1 <- filterAndTrim(nops1, filts1, minQ=3, minLen=100, maxN=0, rm.phix=FALSE, maxEE=8)
track1
```


Dereplicate:
```{r derep1, warning=FALSE, message=FALSE}
drp1 <- derepFastq(filts1, verbose=TRUE)
```

Learn errors:
```{r learn-err1}
err1 <- learnErrors(drp1, errorEstimationFunction=PacBioErrfun, BAND_SIZE=32, multithread=TRUE)
saveRDS(err1, file.path(path.rds, "err_PBB1_2.rds"))
```

Inspect errors:
```{r see-err1}
plotErrors(err1)
```

Looks good.

Denoise:
```{r dada2-sample1}
dd1 <- dada(drp1, err=err1, BAND_SIZE=32, multithread=TRUE)
saveRDS(dd1, file.path(path.rds, "PBB1_dd1_2.rds"))
```

Read tracking for PBB1:
```{r}
cbind(ccs=prim1[,1], primers=prim1[,2], filtered=track1[,2], denoised=sapply(dd1, function(x) sum(x$denoised)))
```

Sequence table:
```{r seqtab1}
st1 <- makeSequenceTable(dd1); dim(st1)
```
Save progress here before moving to PBB2.
```{r save seq table1}
saveRDS(st1, "RDS/PBB1_2.rds")
```


*Repeat for PBB2*

Remove primers and orient reads:
```{r primers2, message=FALSE, warning=FALSE}
nops2 <- file.path(pathPBB2, "noprimers", basename(fnsPBB2))
prim2 <- removePrimers(fnsPBB2, nops2, primer.fwd=B49873_e, primer.rev=dada2:::rc(A50272_f), orient=TRUE)
```

Inspect length distribution.
```{r length-distro}
lens.fn2 <- lapply(nops2, function(fn) nchar(getSequences(fn)))
lens2 <- do.call(c, lens.fn2)
hist(lens2, 100)
min(lens2)
max(lens2)
```

Filter and Trim
maxEE=8
```{r filter2}
filts2 <- file.path(pathPBB2, "noprimers", "filtered", basename(fnsPBB2))
track2 <- filterAndTrim(nops2, filts2, minQ=3, minLen=100, maxN=0, rm.phix=FALSE, maxEE=8)
track2
```

Dereplicate:
```{r derep2, message=FALSE}
drp2 <- derepFastq(filts2, verbose=TRUE)
```

Learn errors:
```{r learn-err2}
err2 <- learnErrors(drp2, errorEstimationFunction=PacBioErrfun, BAND_SIZE=32, multithread=TRUE)
saveRDS(err2, file.path(path.rds, "err_PBB2_2.rds"))
```

Inspect errors:
```{r see-err2}
plotErrors(err2)
```

Looks good.

Denoise:
```{r dada2-sample-2}
dd2 <- dada(drp2, err=err2, BAND_SIZE=32, multithread=TRUE)
saveRDS(dd2, file.path(path.rds, "PBB2_dd2_2.rds"))
```

Read tracking for PBB2:
```{r}
cbind(ccs=prim2[,1], primers=prim2[,2], filtered=track2[,2], denoised=sapply(dd2, function(x) sum(x$denoised)))
```

Sequence table:
```{r seqtab2}
st2 <- makeSequenceTable(dd2); dim(st2)
```

Save progress for PBB2 and next merge datafiles for downstream analyses.
```{r save seq table2}
saveRDS(st2, "RDS/PBB2_2.rds")
```


*Combine all quality-trimmed files*

```{r combine-files}
st1 <- readRDS("RDS/PBB1_2.rds")
st2 <- readRDS("RDS/PBB2_2.rds")
st3 <- readRDS("RDS/PBB3_2.rds")
st.all <- mergeSequenceTables(st1, st2, st3)
```

## Remove chimeras, assign taxonomy and save progress
```{r remove-chimeras}
st.all_chimera_free <- removeBimeraDenovo(st.all, method="consensus", multithread=TRUE, verbose = TRUE)
```

```{r assign taxonomy}
# Assign taxonomy
tax <- assignTaxonomy(st.all, "./trnF_db11Feb22.fa", minBoot = 80, tryRC = TRUE, multithread=TRUE) # Slowest part
head(unname(tax))
```

```{r save-progrss-taxonomy}
# Write to disk
saveRDS(st.all, "RDS/PBB_all_runs_2.rds")
saveRDS(tax, "RDS/PBB_all_runs_tax_2.rds")
```

> NOTE: taxonomy will be improved later, using BLAST (nt database), but only after the ASV table is further cleaned up in Phyloseq

# Move analysis over to Phyloseq
## Load all runs RDS files (ASV table file and taxonomy file)
Also load metadata file, where sample names are row names

```{r phyloseq-load-data}
library(dplyr)
st.all_chimera_free <- readRDS("RDS/PBB_all_runs_2.rds")
tax <- readRDS("RDS/PBB_all_runs_tax_2.rds")
metadata <- read.table("./metadata_assembly/Burrower_bugs_metadata_DEC32024.csv", row.names = 3, sep = ",", header = TRUE) # Note, exclude first column (row number) before loading this spreadsheet
metadata$SequenceBatch <- as.factor(metadata$SequenceBatch)
metadata$collection_date <- as.Date(metadata$collection_date, format = "%m/%d/%y")
metadata$Month <- factor(metadata$Month, levels = month.name)
```

Make Phyloseq object
```{r phyloseq-make-object-1}
p_data <- phyloseq(otu_table(st.all_chimera_free, taxa_are_rows = FALSE),
                   sample_data(metadata),
                   tax_table(tax))
```

Store DNA sequences in different slot and simplify ASV names
```{r phyloseq-format-data}
dna <- Biostrings::DNAStringSet(taxa_names(p_data))
names(dna) <- taxa_names(p_data)
p_data <- merge_phyloseq(p_data, dna)
taxa_names(p_data) <- paste0("ASV", seq(ntaxa(p_data)))
p_data
```

## Decontam
```{r decontam-eval-data}
library(decontam)
df <- as.data.frame(sample_data(p_data))
df$LibrarySize <- sample_sums(p_data)
df <- df[order(df$LibrarySize),]
df$Index <- seq(nrow(df))
ggplot(data=df, aes(x=Index, y=LibrarySize, color=sample_type)) + geom_point()
sample_data(p_data)$is.neg <- sample_data(p_data)$sample_type == "control"

# adopting prevalence method to identify contaminants based on controls
# sensitivity set to low (threhold = 0.1)
contamdf.prev.01 <- isContaminant(p_data, method="prevalence", neg="is.neg")
table(contamdf.prev.01$contaminant)
contaminant.list <- which(contamdf.prev.01$contaminant)
tax_table(p_data)[contaminant.list,]

# sensitivity set to high (threshold = 0.5)
contamdf.prev.05 <- isContaminant(p_data, method="prevalence", neg="is.neg", threshold = 0.5)
table(contamdf.prev.05$contaminant)
contaminant.list <- which(contamdf.prev.05$contaminant)
tax_table(p_data)[contaminant.list,]
```

We identified via PCR that some reagents (e.g. some primer-barcode combinations) were likely contaminated with plant DNA.
Suspect contaminants such as Citrus only show up as contaminant when sensitivity is increased to 0.5.

Let's inspect how contaminants prevalence is divided between control and samples

```{r decontam-eval-distribution}
# Make phyloseq object of presence-absence in negative controls and true samples
ps.pa <- transform_sample_counts(p_data, function(abund) 1*(abund>0))
ps.pa.neg <- prune_samples(sample_data(ps.pa)$sample_type == "control", ps.pa)
ps.pa.pos <- prune_samples(sample_data(ps.pa)$sample_type == "sample", ps.pa)
# Make data.frame of prevalence in positive and negative samples
# for threshold=0.1
df.pa1 <- data.frame(pa.pos=taxa_sums(ps.pa.pos), pa.neg=taxa_sums(ps.pa.neg),
                      contaminant=contamdf.prev.01$contaminant)
ggplot(data=df.pa1, aes(x=pa.neg, y=pa.pos, color=contaminant)) + geom_point() +
  xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples)") + ggtitle("Decontamination threshold=0.1")
# for threshold=0.5
df.pa5 <- data.frame(pa.pos=taxa_sums(ps.pa.pos), pa.neg=taxa_sums(ps.pa.neg),
                      contaminant=contamdf.prev.05$contaminant)
ggplot(data=df.pa5, aes(x=pa.neg, y=pa.pos, color=contaminant)) + geom_point() +
  xlab("Prevalence (Negative Controls)") + ylab("Prevalence (True Samples)") + ggtitle("Decontamination threshold=0.5")

p_data.ord <- ordinate(p_data, "PCoA", "bray")
plot_ordination(p_data, p_data.ord, type="sample", color="sample_type", shape="SequenceBatch")+ geom_point(size=3)
```

Because it is hard to distinguish whether contaminated primers were contaminated by the samples themselves, or whether it was contaminated water that was used for dilution, or both (likely), there is a risk that a more rigorous cutoff for contaminants will likely remove false-positives as well.
On the other hand, a soft filter may leave out some likely contaminants such as Citrus.
```{r decontam-clean-data}
p_data.noncontam <- prune_taxa(!contamdf.prev.05$contaminant, p_data)
p_data
p_data.noncontam
# Remove control samples from analysis
p_data.clean <-subset_samples(p_data.noncontam, sample_type!="control")
# Remove samples with zero ASV (zero column sums)
p_data.clean <- subset_samples(p_data.clean, sample_sums(p_data.clean) > 0)
```


> At this point, the taxonomy table is likely to contain fewer (or no) spurious sequences
> Therefore, this is a good point to export the taxonomy table as a fasta file and run Blast to improve genus assignment (i.e. replace NAs)

#### Save taxonomy table

```{r save-taxonomy-table}
p_data.clean %>%
  tax_table() %>%
  write.csv("./PBB123_asv_11182024.csv")
```

#### Save sequences as a fasta file for blast, use the following command
```{r save-sequences-fasta}
p_data.clean %>%
      refseq() %>%
      Biostrings::writeXStringSet("./PBB123_asv_11182024.fasta", append=FALSE,
                                  compress=FALSE, compression_level=NA, format="fasta")
```

#### Save decontaminated phyloseq object and its components

```{r save-progress}
saveRDS(otu_table(p_data.clean), "RDS/p_data.cleanOTU.rds")
saveRDS(sample_data(p_data.clean), "RDS/p_data.cleanSampleData.rds")
saveRDS(tax_table(p_data.clean), "RDS/p_data.cleanOTUTaxaTable.rds")
saveRDS(refseq(p_data.clean), "RDS/p_data.cleanOTURefSeq.rds")
```


> This concludes part 1 of cleaning, denoising and classifying sequences in these samples. The next portion, part 2, is focused on determining taxonomy for some of the undetermined taxa, as well as excluding taxa that aren't relevant for this study, such as bryphoyte and algae.

# Part 2, adding results from blast search

Prepare environment:

Load Data

```{r phyloseq-load-improved-data}
p_data.cleanOTU <- readRDS("RDS/p_data.cleanOTU.rds")
p_data.cleanSampleData <- readRDS("RDS/p_data.cleanSampleData.rds")
p_data.cleanOTUTaxaTable <- readRDS("RDS/p_data.cleanOTUTaxaTable.rds")
p_data.cleanOTURefSeq <- readRDS("RDS/p_data.cleanOTURefSeq.rds")
```

Make Phyloseq object
```{r phyloseq-make-object}
p_data.clean <- phyloseq(otu_table(p_data.cleanOTU, taxa_are_rows = FALSE),
                   sample_data(p_data.cleanSampleData),
                   tax_table(p_data.cleanOTUTaxaTable),
                   refseq(p_data.cleanOTURefSeq))
```


>Blast was executed using script in blast_ASV_pbb123.sh
PBB123_asv_11182024.csv (taxonomy table) was edited and every NA was changed if taxonomic information was available (a blast hit result)
NOTE: taxonomical assignments ranged from about 95% to 100% and some NAs remained with no classification via Blast

#### Add new taxonomical information to Phyloseq object

```{r add-new-taxon-table}
new_tax_table <- read.csv("PBB123_asv_11182024.csv", row.names = 1)
new_tax <- tax_table(as.matrix(new_tax_table))
tax_table(p_data.clean) <- new_tax
```

## Further cleaning taxonomical data

List all instances where Genus == NA
```{r list-genus-NA}
#tax_table(p_data.clean) %>% as("matrix") %>% as_tibble
p_data.clean %>%
  subset_taxa(is.na(Genus)) %>%
 tax_table()
```

All but a few instance of Genus=NA are ASV where Kingdom is also NA. As a conservative approach, I will exclude everything that is not identified as Viridiplantae at the Kingdom level

Remove singletons if needed and taxa where Order = NA
Remove instances where algae was identified
Remove samples where count is zero

```{r prepare-for-downstream-diversity-analysis}
tail(taxa_sums(p_data.clean) < 2)
p_data.clean <- prune_taxa(taxa_sums(p_data.clean) > 1, p_data.clean) %>% subset_taxa(., Kingdom == "Viridiplantae")
p_data.clean <- subset_samples(p_data.clean, sample_sums(p_data.clean) > 0)
```

Sanity check - is there any NA left for Genus?
```{r list-genus-NA-2}
#tax_table(p_data.clean) %>% as("matrix") %>% as_tibble
p_data.clean %>%
  subset_taxa(is.na(Genus)) %>%
 tax_table()
```

These ASVs have an inconclusive identification for Genus. In addition, there is taxa here that are still likely not part of these bugs' diet (e.g. Bryophytes).

Checking for mosses and other unexpected taxa
```{r are-there-mosses}
# are there unexpected taxa?
unique(tax_table(p_data.clean)[,3])
```

Mosses are the only unexpected taxa.
Remove mosses with the following command
```{r remove-mosses}
# How many ASVs are mosses?
p_data.clean %>% subset_taxa(., Class == "Bryopsida") %>% tax_table() # two ASVs
p_data.clean
p_data.clean <- subset_taxa(p_data.clean, Class != "Bryopsida")
p_data.clean # now there are two fewer ASVs
```

```{r save-progress-2}
saveRDS(otu_table(p_data.clean), "RDS/p_data.cleanOTU_cleaningcompleted.rds")
saveRDS(sample_data(p_data.clean), "RDS/p_data.cleanSampleData_cleaningcompleted.rds")
saveRDS(tax_table(p_data.clean), "RDS/p_data.cleanOTUTaxaTable_cleaningcompleted.rds")
saveRDS(refseq(p_data.clean), "RDS/p_data.cleanOTURefSeq_cleaningcompleted.rds")
```

>This concludes part 2 of (the bulk of) cleaning up and classifying data. Next, in part 3, I do more hypothesis-guided analyses, including figures and statistical tests.

#Part 3, figures, ordination and statistical tests

Load Data

```{r phyloseq-load-improved-data}
p_data.cleanOTU <- readRDS("RDS/p_data.cleanOTU_cleaningcompleted.rds")
metadata <- readRDS("RDS/p_data.cleanSampleData_cleaningcompleted.rds")
p_data.cleanOTUTaxaTable <- readRDS("RDS/p_data.cleanOTUTaxaTable_cleaningcompleted.rds")
p_data.cleanOTURefSeq <- readRDS("RDS/p_data.cleanOTURefSeq_cleaningcompleted.rds")
```

Make Phyloseq object
```{r phyloseq-make-object}
p_data.clean <- phyloseq(otu_table(p_data.cleanOTU, taxa_are_rows = FALSE),
                   sample_data(metadata),
                   tax_table(p_data.cleanOTUTaxaTable),
                   refseq(p_data.cleanOTURefSeq))
```

## Rarefaction
Basic stats and rarefying data

First let's separate the data into two different groups: data for the peanut burrower bug _Pangaeus_ _bilineatus_ and data belonging to _Dallasiellus_ _lugubris_

```{r separate-species-2}
p_data.clean_batch1out <- subset_samples(p_data.clean, SequenceBatch != "1") # exclude "batch 1" which is data without a validated species ID
Pbilineatus <- subset_samples(p_data.clean_batch1out, Sp.ID=="Pbilineatus") %>% prune_taxa(taxa_sums(.) > 1, .)
Dlugubris <- subset_samples(p_data.clean_batch1out, Sp.ID=="Dlugubris") %>% prune_taxa(taxa_sums(.) > 1, .)
Pbilineatus
Dlugubris
```

From 34 samples identified as P. bilineatus, only 22 samples passed our quality control. There are another 32 samples that were initially identified as P. bilineatus, but we were not able to validate this identification by molecular methods (i.e. alignment against our reference genome) because the genomes of these samples were not sequenced (RAD-seq). However, we may include these samples back later in this analysis, in case we find significant differences between the diet of these two species that may allow us to classify these samples according to their diet.

From 67 samples identified as D. lugubris, 61 samples passed our quality control.

Now, what is the sample size variation per species?
```{r sample-size-variation-2}
# P. bilineatus
len_samplepb <- as.data.frame(sample_sums(Pbilineatus))
median(len_samplepb$`sample_sums(Pbilineatus)`)
mean(len_samplepb$`sample_sums(Pbilineatus)`)
min(len_samplepb$`sample_sums(Pbilineatus)`)
max(len_samplepb$`sample_sums(Pbilineatus)`)
# D. lugubris
len_sampledl <- as.data.frame(sample_sums(Dlugubris))
median(len_sampledl$`sample_sums(Dlugubris)`)
mean(len_sampledl$`sample_sums(Dlugubris)`)
min(len_sampledl$`sample_sums(Dlugubris)`)
max(len_sampledl$`sample_sums(Dlugubris)`)
```

To visualize distribution in each case, I will exclude the largest samples and focus on the other samples

```{r plot-sample-size-pbilineatus}
#Exclude largest samples to build histogram
len_samplepb <-subset(len_samplepb, len_samplepb$`sample_sums(Pbilineatus)` < 1200)
median(len_samplepb$`sample_sums(Pbilineatus)`)
hist(len_samplepb$`sample_sums(Pbilineatus)`, 10)
```

```{r plot-sample-size-dlugubris}
#Exclude largest samples to build histogram
len_sampledl <-subset(len_sampledl, len_sampledl$`sample_sums(Dlugubris)` < 1200)
median(len_sampledl$`sample_sums(Dlugubris)`)
hist(len_sampledl$`sample_sums(Dlugubris)`, 10)
```

When extremely large samples are excluded, average number of reads per sample is under 100 reads per sample for either species.
Rarefying samples at 100 reads per sample would keep close to half of the samples for each species in the dataset. So, a higher replicate size at the individual level (insect) at the cost of shallower sampling of the diet per individual. However, using a higher sample size cutoff for diet may be better to characterize food items commonly consumed by these insects, at the cost of decreasing the replication at the individual (insect) sampling size. Since the cutoff is the same, then I can rarefy the p_data.clean, to run statistics to compare both species directly. If necessary, I can separate samples as well after they are rarefied.

How many samples do I loose by keeping only samples with a relatively deeper sequencing of diet?
Rather than arbitrarily picking a single sequencing depth, I will compare the relative thresholds and number of samples kept in the dataset using quartiles (25,50,75) of the sample size variation in this dataset as a whole, using 1000 iterations via the rarefaction function from the metagMisc package.

```{r rarefy-function-from-metagMisc}
#devtools::install_github("vmikk/metagMisc")
library(metagMisc)
```

```{r rarefy-data}
p_data.clean_rarefy <- subset_samples(p_data.clean, Site != "Colony") # exclude captive burrower bugs only fed peanuts
otu_table(p_data.clean_rarefy) <- otu_table(t(otu_table(p_data.clean_rarefy)), taxa_are_rows=TRUE)
sample_size_quantile <- as.data.frame(quantile(sample_sums(p_data.clean_rarefy), probs = c(0, 0.10, 0.15, 0.225, 0.25, 0.5, 0.75, 1)))
threshold25 <- sample_size_quantile["25%", ]
threshold50 <- sample_size_quantile["50%", ]
threshold75 <- sample_size_quantile["75%", ]
PBB_rr25 <- phyloseq_mult_raref_avg(p_data.clean_rarefy, SampSize = threshold25, iter=1000, parallel = TRUE,verbose = TRUE)
PBB_rr50 <- phyloseq_mult_raref_avg(p_data.clean_rarefy, SampSize = threshold50, iter=1000, parallel = TRUE,verbose = TRUE)
PBB_rr75 <- phyloseq_mult_raref_avg(p_data.clean_rarefy, SampSize = threshold75, iter=1000, parallel = TRUE,verbose = TRUE)
PBB_rr25 <- transform_sample_counts(PBB_rr25, function(x){ x * threshold25})
PBB_rr50 <- transform_sample_counts(PBB_rr50, function(x){ x * threshold50})
PBB_rr75 <- transform_sample_counts(PBB_rr75, function(x){ x * threshold75})
p_data.clean_rarefy
PBB_rr25
PBB_rr50
PBB_rr75
```

## Are their diets different?

To test if their diets are different, I will use a Permanova test. One of the assumptions of this test is that variance is similar between the groups being compared (i.e. Pangaeus and Dallasiellus). To test if data dispersion is the same between groups, I am using betadisper.

> From hereafter, I choose rarefaction at the 50% quartile depth, since it is the middle trade-off between number of samples and sequences per sample.

```{r prepare_data_rr50}
permanova_rr50 <- subset_samples(PBB_rr50, Sp.ID !="unknown") %>% prune_taxa(taxa_sums(.) > 1, .)
permanova_rr50 <- prune_samples(!is.na(sample_data(permanova_rr50)$Sp.ID), permanova_rr50)
```

```{r betadisper}
# Extract OTU table from phyloseq object, calculate Bray-Curtis distances, and calculate beta dispersion

otu_table <- t(as(otu_table(permanova_rr50), "matrix"))
bray_dist <- vegdist(otu_table, method = "bray")
metadata_rr50 <- data.frame(sample_data(permanova_rr50))

disper_SpID <- betadisper(bray_dist, metadata_rr50$Sp.ID)

# Test if dispersion between groups is significant
anova(disper_SpID)
```

Test is significant (p < 0.05). Permanova may be robust even when dispersion of data is unequal among groups being compared. However, I suspect that unequal sampling in months and sites may cofound the test here (that is, for instance, if one species is more collected in one month/year and the other in a different month/year, diet may reflect plants available rather than differences in diet). Permanova is less robust for unequal sampling designs.

How unequal is sampling (month and sites)?

```{r sampling-design-rr50}
# Pbilineatus data (30 samples total)
# Month
filter(metadata_rr50, Sp.ID == "Pbilineatus") %>% group_by(Month) %>% summarize(month = length(Month)) # Mostly June, 19 samples
# Year
filter(metadata_rr50, Sp.ID == "Pbilineatus") %>% group_by(Year) %>% summarize(year = length(Year)) # Mostly 2020, 28 samples
# Sites
filter(metadata_rr50, Sp.ID == "Pbilineatus") %>% group_by(Site) %>% summarize(site = length(Site)) # Randolph: 12, Worth: 18

# Dlugubris data (31 samples total)
# Month
filter(metadata_rr50, Sp.ID == "Dlugubris") %>% group_by(Month) %>% summarize(months = length(Month)) # Mostly September, 24 samples
# Year
filter(metadata_rr50, Sp.ID == "Dlugubris") %>% group_by(Year) %>% summarize(year = length(Month)) # Mostly 2021, 28 samples
# Sites
filter(metadata_rr50, Sp.ID == "Dlugubris") %>% group_by(Site) %>% summarize(site = length(Site)) # Mostly Worth, 30 samples
```

The counts above indicate that although sampling per species is similar (30 and 31 samples for _Pangaeus_ and _Dallasiellus_, respectively), sampling was heavily biased towards non-overlapping months between species and, to a lesser extent, less overlap in sampling regions. Because plant phenology and flora composition may change significantly between Summer (e.g. June) and Fall (e.g. September), it may be difficult to distinguish diet differences between species due to month of sampling or species identity, or both.

I will test this data first assuming no differences due to month of sampling, but I will have Species nested in site, since it is less likely that sampling locations will be identical in their landscape and, thus, plant diversity.

But first, I need to address the issue of overdispersed data. I will use weighted UniFrac distances, that uses a phylogenetic approach to weigh the relative abundance of similar clades in community composition when comparing the dissimilarity between samples.

1. I start by making a phylogenetic tree of _trnF_ sequences, required for calculating UniFrac distances (this step takes long to be completed)
```{r tree-for-UniFrac-distances}
library(phangorn)
library(DECIPHER)
asv_ids <- colnames(otu_table)
refseq_phyloseq <- refseq(p_data.clean_rarefy)
refseq_phyloseq_rr50 <- refseq_phyloseq[names(refseq_phyloseq) %in% asv_ids]
permanova_rr50up <- merge_phyloseq(permanova_rr50, refseq_phyloseq_rr50)
alignment <- AlignSeqs(refseq_phyloseq_rr50, anchor=NA)
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm)
mod.test <- modelTest(phangAlign) #this gives TVM+G(4)+I as the best model
fit = pml(treeNJ, data=phangAlign)
fitTVM <- update(fit, k=4, inv=0.2)
fitTVM <- optim.pml(fitTVM, model="TVM", optInv=TRUE, optGamma=TRUE,
        rearrangement = "stochastic", control = pml.control(trace = 0)) #this may take 15-20 min
detach("package:phangorn", unload=TRUE)
permanova_rr50up_phytree <- merge_phyloseq(permanova_rr50up, fitTVM$tree)
```

2. Next, I calculate if data is still overdispersed using betadisper
```{r betadisper-UniFrac}
unifrac_dist <- UniFrac(permanova_rr50up_phytree, weighted = TRUE)
disper50_unifrac <- betadisper(unifrac_dist, metadata_rr50$Sp.ID)
anova(disper50_unifrac) #this result meets permanova assumptions (p>0.05)
```

Data is no longer overdispersed with UniFrac distances. We meet the Permanova assumption of similar dispersion!

3. Permanova

3.1. First define permanova terms
```{r permanova-terms}
Site_50 <- sample_data(permanova_rr50)$Site
Month_50 <- sample_data(permanova_rr50)$Month
Species_50 <- sample_data(permanova_rr50)$Sp.ID
```

3.2. Testing the relative importance of Month as a co-variable. Note that Species is nested in Site, to account for site-specific variation in landscape
```{r permanovaNoStrata}
adonis2(formula = unifrac_dist ~ Species_50/Site_50 + Month_50, data = metadata, permutations = 999) # Species p = 0.019, Month p = 0.067, Species:Site p = 0.164
```

3.3. Month is marginally significant! I will test the data one more time, but using Month as strata (or block).
```{r permanovMonthAsStrata}
adonis2(formula = unifrac_dist ~ Species_50/Site_50, data = metadata, permutations = 999, strata = Month_50) # Species p = 0.297, Species:Site p =0.158
```

The results are clear, we are not able to tell if diet is different between these two species because month of sampling is a cofounding variable.

## Ordination
```{r ordination-microviz}
#Load required packages
library(cowplot)
library(microViz)
library(phangorn)
# Make a tree for all rarefaction depths
alignment <- AlignSeqs(refseq(p_data.clean_rarefy), anchor=NA)
phangAlign <- phyDat(as(alignment, "matrix"), type="DNA")
dm <- dist.ml(phangAlign)
treeNJ <- NJ(dm) 
mod.test <- modelTest(phangAlign) #this gives TVM+G(4)+I as the best model
fit = pml(treeNJ, data=phangAlign)
fitTVM <- update(fit, k=4, inv=0.2)
fitTVM <- optim.pml(fitTVM, model="TVM", optInv=TRUE, optGamma=TRUE,
        rearrangement = "stochastic", control = pml.control(trace = 0)) #this may take 15-20 min
detach("package:phangorn", unload=TRUE)

# Add tree to rarefied datasets
PBB_rr25 <- merge_phyloseq(PBB_rr25, fitTVM$tree)
PBB_rr50 <- merge_phyloseq(PBB_rr50, fitTVM$tree)
PBB_rr75 <- merge_phyloseq(PBB_rr75, fitTVM$tree)

# List of dataset names
dataset_names <- c("PBB_rr25", "PBB_rr50", "PBB_rr75")

# Initialize an empty list to store results
plots <- list()

# Loop through each dataset
for (name in dataset_names) {
  # Dynamically access the dataset using get()
  dataset <- get(name)

  # Perform the operations
  dataset_sub <- subset_samples(dataset, Sp.ID != "unknown") %>% prune_taxa(taxa_sums(.) > 1, .)
  dataset_sub <- prune_samples(!is.na(sample_data(dataset_sub)$Sp.ID), dataset_sub)
forpcoa <- tax_fix(dataset_sub)
forpcoa <- phyloseq_validate(forpcoa, remove_undetected = TRUE)
plot <- forpcoa %>%
  tax_transform("identity", rank = "Genus") %>%
  dist_calc("wunifrac") %>%
  ord_calc(method = "PCoA") %>%
  ord_plot(color = "Sp.ID", size =3) +
  scale_colour_brewer(palette = "Paired", aesthetics = c("fill", "colour")) +
  theme_bw() +
  ggside::geom_xsideboxplot(aes(fill = Sp.ID, y = Sp.ID), orientation = "y") +
  ggside::geom_ysideboxplot(aes(fill = Sp.ID, x = Sp.ID), orientation = "x") +
  ggside::scale_xsidey_discrete(labels = NULL) +
  ggside::scale_ysidex_discrete(labels = NULL) +
  ggside::theme_ggside_void()

  # Add plot to the list
  plots[[name]] <- plot
}

# Combine plots into a single figure using cowplot
combined_plot <- plot_grid(
  plots$PBB_rr25,
  plots$PBB_rr50,
  plots$PBB_rr75,
  labels = c("A", "B", "C"), # Add labels if needed
  ncol = 1 # Arrange plots in a single column
)

# Display the combined plot
print(combined_plot)
ggsave("Figures/PCoA_wunifrac_boxplot.pdf",height=21,width=12)

```

Alternative PCoA visualization

```{r ordination}
# For all data
# Load required packages
library(cowplot)

# List of dataset names
dataset_names <- c("PBB_rr25", "PBB_rr50", "PBB_rr75")

# Initialize an empty list to store results
plots <- list()

# Loop through each dataset
for (name in dataset_names) {
  # Dynamically access the dataset using get()
  dataset <- get(name)

  # Perform the operations
  dataset_sub <- subset_samples(dataset, Sp.ID != "unknown") %>% prune_taxa(taxa_sums(.) > 1, .)
  dataset_sub <- prune_samples(!is.na(sample_data(dataset_sub)$Sp.ID), dataset_sub) %>% tax_glom("Genus")

  dataset_ord <- ordinate(dataset_sub, "PCoA", "euclidean")
  plot <- plot_ordination(dataset_sub, dataset_ord, type = "sample", color = "Sp.ID",
                          title = paste("Diet Variation \n rarefy depth:", substr(name, 7, 8))) +
    geom_point(alpha = 0.5, size = 8) +
    #scale_fill_manual(values = c("red", "blue")) +
      #stat_ellipse(geom = "polygon",
               #aes(fill = "Sp.ID"),
               #alpha = 0.25)
  stat_ellipse(type = "norm", linetype = 2) +
  theme_classic() +
  geom_point(size=4) + scale_color_manual(values = c("gray", "red")) +
  theme(strip.background = element_blank(), text = element_text(size = 12))
  # Add plot to the list
  plots[[name]] <- plot
}

# Combine plots into a single figure using cowplot
combined_plot <- plot_grid(
  plots$PBB_rr25,
  plots$PBB_rr50,
  plots$PBB_rr75,
  labels = c("A", "B", "C"), # Add labels if needed
  ncol = 1 # Arrange plots in a single column
)

# Display the combined plot
print(combined_plot)
ggsave("./Figures/PCoA_euclidean.pdf", width=10, height=15)

```
